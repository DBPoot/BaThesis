{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh7AaFb1Pa4J"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModelForMaskedLM, set_seed\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HFxcdcqhOOsH"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"GroNLP/dutch-cola\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HDRP6puMPZeJ"
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame.from_dict(dataset[\"train\"])\n",
        "dev_df = pd.DataFrame.from_dict(dataset[\"validation\"])\n",
        "test_df = pd.DataFrame.from_dict(dataset[\"test\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "l5T5lBm5QvGc",
        "outputId": "d9cd077c-63e8-4a57-f80e-e5c4bce03e7b"
      },
      "outputs": [],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVb3F5xWPRR_",
        "outputId": "334e45a2-a11d-49ed-8f14-eeba76c47c69"
      },
      "outputs": [],
      "source": [
        "# Initiate Model\n",
        "model_name = 'GroNLP/bert-base-dutch-cased' # or other model if preferred\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b5XQNiR7rDfH"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.sample(frac=1, random_state=42) # shuffle train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5Ffz7iBRf09",
        "outputId": "ad9768a9-eac3-4421-df08-1b388bd77015"
      },
      "outputs": [],
      "source": [
        "# Create embeddings of train data\n",
        "train_cls_embeddings = {\n",
        "  1: [],\n",
        "  2: [],\n",
        "  3: [],\n",
        "  4: [],\n",
        "  5: [],\n",
        "  6: [],\n",
        "  7: [],\n",
        "  8: [],\n",
        "  9: [],\n",
        "  10: [],\n",
        "  11: [],\n",
        "  12: []\n",
        "}\n",
        "for line in tqdm(train_df[\"Sentence\"]):\n",
        "  tokenized_text = tokenizer(line, return_tensors=\"pt\")\n",
        "  with torch.no_grad():\n",
        "    line_embedding = model(**tokenized_text, output_hidden_states=True) # extract embedding for sentence\n",
        "\n",
        "  for i in range(1,13):\n",
        "    train_cls_embeddings[i].append(line_embedding.hidden_states[i][:, -1, :]) # store embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YncQXaf_VMxO",
        "outputId": "f4770bf8-eac1-4308-f023-711202b053f4"
      },
      "outputs": [],
      "source": [
        "# Create embeddings of test data\n",
        "test_cls_embeddings = {\n",
        "  1: [],\n",
        "  2: [],\n",
        "  3: [],\n",
        "  4: [],\n",
        "  5: [],\n",
        "  6: [],\n",
        "  7: [],\n",
        "  8: [],\n",
        "  9: [],\n",
        "  10: [],\n",
        "  11: [],\n",
        "  12: []\n",
        "}\n",
        "for line in tqdm(test_df[\"Sentence\"]):\n",
        "  tokenized_text = tokenizer(line, return_tensors=\"pt\")\n",
        "  with torch.no_grad():\n",
        "    line_embedding = model(**tokenized_text, output_hidden_states=True) # extract embedding for sentence\n",
        "\n",
        "  for i in range(1,13):\n",
        "    test_cls_embeddings[i].append(line_embedding.hidden_states[i][:, -1, :]) # store embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for layer in range(1,13):\n",
        "  print(layer)\n",
        "  print(\"===============\")\n",
        "\n",
        "  # Create numpy objects of embeddings\n",
        "  X_train = [tensor.numpy() for tensor in train_cls_embeddings[layer]]\n",
        "  X_test = [tensor.numpy() for tensor in test_cls_embeddings[layer]] # set to dev for testing accuracy\n",
        "\n",
        "  # extract labels from CoLA\n",
        "  y_train = train_df['Acceptability']\n",
        "  y_test = test_df['Acceptability']\n",
        "\n",
        "  # initiate SVC model\n",
        "  clf = svm.SVC(kernel='linear')\n",
        "\n",
        "  # train the model\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  print(\"Model trained.\")\n",
        "\n",
        "  # predict labels\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  ac_score = metrics.accuracy_score(y_test, y_pred)\n",
        "  rc_score = metrics.recall_score(y_test, y_pred)\n",
        "  pr_score = metrics.precision_score(y_test, y_pred)\n",
        "  f1_score = metrics.f1_score(y_test, y_pred)\n",
        "\n",
        "  print(\"---------------\")\n",
        "  print(f\"Accuracy: {ac_score:.3f}\\nRecall: {rc_score:.3f}\\nPrecision: {pr_score:.3f}\\nF1: {f1_score:.3f}\")\n",
        "  print(f\"{ac_score:.3f}, {rc_score:.3f}, {pr_score:.3f}, {f1_score:.3f}\")\n",
        "  print(\"===============\")\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
