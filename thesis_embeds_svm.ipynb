{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jh7AaFb1Pa4J"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModelForMaskedLM, set_seed\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HFxcdcqhOOsH"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"GroNLP/dutch-cola\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HDRP6puMPZeJ"
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame.from_dict(dataset[\"train\"])\n",
        "dev_df = pd.DataFrame.from_dict(dataset[\"validation\"])\n",
        "test_df = pd.DataFrame.from_dict(dataset[\"test\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "l5T5lBm5QvGc",
        "outputId": "d9cd077c-63e8-4a57-f80e-e5c4bce03e7b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>Original ID</th>\n",
              "      <th>Acceptability</th>\n",
              "      <th>Original annotation</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Material added</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SoD-Noun2</td>\n",
              "      <td>4.1a</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>Ik geef een paar voorbeelden.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SoD-Noun2</td>\n",
              "      <td>4.1b</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>Ik geef twee voorbeelden.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SoD-Noun2</td>\n",
              "      <td>4.1b</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>Ik geef enkele voorbeelden.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SoD-Noun2</td>\n",
              "      <td>4.3a</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>Ik heb een paar schoenen.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SoD-Noun2</td>\n",
              "      <td>4.3b</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>Ik zag het paar schoenen.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19888</th>\n",
              "      <td>SoD-Zw</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>Hij ging naar de prachtige eilanden.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19889</th>\n",
              "      <td>SoD-Zw</td>\n",
              "      <td>5.2a</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>Hij wilde naar die prachtige eilanden.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19890</th>\n",
              "      <td>SoD-Zw</td>\n",
              "      <td>5.2a</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>Ze wees naar deze prachtige eilanden.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19891</th>\n",
              "      <td>SoD-Zw</td>\n",
              "      <td>5.2b</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>Ze gingen naar hun prachtige eilanden.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19892</th>\n",
              "      <td>SoD-Zw</td>\n",
              "      <td>5.5</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>Ze gingen langs alle prachtige eilanden.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19893 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Source Original ID  Acceptability Original annotation  \\\n",
              "0      SoD-Noun2        4.1a              1                None   \n",
              "1      SoD-Noun2        4.1b              1                None   \n",
              "2      SoD-Noun2        4.1b              1                None   \n",
              "3      SoD-Noun2        4.3a              1                None   \n",
              "4      SoD-Noun2        4.3b              1                None   \n",
              "...          ...         ...            ...                 ...   \n",
              "19888     SoD-Zw         5.1              1                None   \n",
              "19889     SoD-Zw        5.2a              1                None   \n",
              "19890     SoD-Zw        5.2a              1                None   \n",
              "19891     SoD-Zw        5.2b              1                None   \n",
              "19892     SoD-Zw         5.5              1                None   \n",
              "\n",
              "                                       Sentence  Material added  \n",
              "0                 Ik geef een paar voorbeelden.               1  \n",
              "1                     Ik geef twee voorbeelden.               1  \n",
              "2                   Ik geef enkele voorbeelden.               1  \n",
              "3                     Ik heb een paar schoenen.               1  \n",
              "4                     Ik zag het paar schoenen.               1  \n",
              "...                                         ...             ...  \n",
              "19888      Hij ging naar de prachtige eilanden.               0  \n",
              "19889    Hij wilde naar die prachtige eilanden.               1  \n",
              "19890     Ze wees naar deze prachtige eilanden.               1  \n",
              "19891    Ze gingen naar hun prachtige eilanden.               0  \n",
              "19892  Ze gingen langs alle prachtige eilanden.               0  \n",
              "\n",
              "[19893 rows x 6 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVb3F5xWPRR_",
        "outputId": "334e45a2-a11d-49ed-8f14-eeba76c47c69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Initiate Model\n",
        "model_name = 'GroNLP/bert-base-dutch-cased' # or other model if preferred\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b5XQNiR7rDfH"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.sample(frac=1, random_state=42) # shuffle train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5Ffz7iBRf09",
        "outputId": "ad9768a9-eac3-4421-df08-1b388bd77015"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19893/19893 [18:16<00:00, 18.13it/s]\n"
          ]
        }
      ],
      "source": [
        "# Create embeddings of train data\n",
        "train_cls_embeddings = {\n",
        "  1: [],\n",
        "  2: [],\n",
        "  3: [],\n",
        "  4: [],\n",
        "  5: [],\n",
        "  6: [],\n",
        "  7: [],\n",
        "  8: [],\n",
        "  9: [],\n",
        "  10: [],\n",
        "  11: [],\n",
        "  12: []\n",
        "}\n",
        "for line in tqdm(train_df[\"Sentence\"]):\n",
        "  tokenized_text = tokenizer(line, return_tensors=\"pt\")\n",
        "  with torch.no_grad():\n",
        "    line_embedding = model(**tokenized_text, output_hidden_states=True) # extract embedding for sentence\n",
        "\n",
        "  for i in range(1,13):\n",
        "    train_cls_embeddings[i].append(line_embedding.hidden_states[i][:, -1, :]) # store embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YncQXaf_VMxO",
        "outputId": "f4770bf8-eac1-4308-f023-711202b053f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2400/2400 [02:13<00:00, 18.01it/s]\n"
          ]
        }
      ],
      "source": [
        "# Create embeddings of test data\n",
        "test_cls_embeddings = {\n",
        "  1: [],\n",
        "  2: [],\n",
        "  3: [],\n",
        "  4: [],\n",
        "  5: [],\n",
        "  6: [],\n",
        "  7: [],\n",
        "  8: [],\n",
        "  9: [],\n",
        "  10: [],\n",
        "  11: [],\n",
        "  12: []\n",
        "}\n",
        "for line in tqdm(test_df[\"Sentence\"]):\n",
        "  tokenized_text = tokenizer(line, return_tensors=\"pt\")\n",
        "  with torch.no_grad():\n",
        "    line_embedding = model(**tokenized_text, output_hidden_states=True) # extract embedding for sentence\n",
        "\n",
        "  for i in range(1,13):\n",
        "    test_cls_embeddings[i].append(line_embedding.hidden_states[i][:, -1, :]) # store embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "===============\n",
            "Model trained.\n",
            "---------------\n",
            "Accuracy: 0.662\n",
            "Recall: 0.839\n",
            "Precision: 0.620\n",
            "F1: 0.713\n",
            "0.662, 0.839, 0.620, 0.713\n",
            "===============\n",
            "11\n",
            "===============\n",
            "Model trained.\n",
            "---------------\n",
            "Accuracy: 0.674\n",
            "Recall: 0.849\n",
            "Precision: 0.629\n",
            "F1: 0.722\n",
            "0.674, 0.849, 0.629, 0.722\n",
            "===============\n",
            "12\n",
            "===============\n",
            "Model trained.\n",
            "---------------\n",
            "Accuracy: 0.674\n",
            "Recall: 0.848\n",
            "Precision: 0.629\n",
            "F1: 0.722\n",
            "0.674, 0.848, 0.629, 0.722\n",
            "===============\n"
          ]
        }
      ],
      "source": [
        "for layer in range(1,13):\n",
        "  print(layer)\n",
        "  print(\"===============\")\n",
        "\n",
        "  # Create numpy objects of embeddings\n",
        "  X_train = [tensor.numpy() for tensor in train_cls_embeddings[layer]]\n",
        "  X_test = [tensor.numpy() for tensor in test_cls_embeddings[layer]] # set to dev for testing accuracy\n",
        "\n",
        "  # extract labels from CoLA\n",
        "  y_train = train_df['Acceptability']\n",
        "  y_test = test_df['Acceptability']\n",
        "\n",
        "  # initiate SVC model\n",
        "  clf = svm.SVC(kernel='linear')\n",
        "\n",
        "  # train the model\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  print(\"Model trained.\")\n",
        "\n",
        "  # predict labels\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  ac_score = metrics.accuracy_score(y_test, y_pred)\n",
        "  rc_score = metrics.recall_score(y_test, y_pred)\n",
        "  pr_score = metrics.precision_score(y_test, y_pred)\n",
        "  f1_score = metrics.f1_score(y_test, y_pred)\n",
        "\n",
        "  print(\"---------------\")\n",
        "  print(f\"Accuracy: {ac_score:.3f}\\nRecall: {rc_score:.3f}\\nPrecision: {pr_score:.3f}\\nF1: {f1_score:.3f}\")\n",
        "  print(f\"{ac_score:.3f}, {rc_score:.3f}, {pr_score:.3f}, {f1_score:.3f}\")\n",
        "  print(\"===============\")\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
